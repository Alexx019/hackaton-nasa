Summary
While your cell phone screen can display about three million pixels of information and your eye can receive more than ten million pixels, NASA images from space are even bigger! NASA’s space missions continue to push the boundaries of what is technologically possible, providing high-resolution images and videos of Earth, other planets, and space with billions or even trillions of pixels. Your challenge is to create a platform that allows users to zoom in and out on these massive image datasets, label known features, and discover new patterns.

Background
NASA’s missions are taking pictures of Earth, other planets, and the distant universe using increasingly faster data rates to provide very detailed, high-resolution images. Think about a 10-megapixel picture in your phone’s camera file and compare that to the 10-gigapixel images of space and 10-terapixel visual datasets available from NASA. The amount of visual information available from space can feel overwhelming, and it is only expected to grow in the coming years.

For instance, the largest Hubble image is a 2.5-gigapixel picture of the Andromeda galaxy. Each day, the Mars Color Imager onboard the Mars Reconnaissance Orbiter (MRO) provides a gigapixel-level global map of the red planet in seven different colors. Exploring these giant images is challenging since we don’t have tools to take in all of this visual information at once. Currently, the EarthData site displays images of Earth taken by NASA satellites multiple times a day. Maps of the Moon made by the Lunar Reconnaissance Orbiter provide gigapixel-scale pictures of the surface of the nearest celestial body. NASA’s Solar System Treks platform allows users to navigate the surface of various moons and planets using real data collected by spacecraft. But what additional discoveries could be made, and what inspiration could people find, if there were tools to make exploring the data more rapid and seamless?

Imagine being able to zoom into a dust storm on Mars or compare detailed images of a galaxy taken years apart from the same position. Current tools for exploring these data sets are not very user-friendly, or only show us parts of images rather than allowing us to see the full picture.

New ideas are needed to bring these enormous datasets to life – especially those that change over time – to enable both learning and discovery.

Objectives
Your challenge is to create a platform that allows users to zoom in and out of NASA’s massive image datasets, label known features, and discover new patterns. Datasets you might use could be sequences of Earth observations, lunar maps, or giant images of space. Your solution could be a way of scanning through these huge images, or a new tool for examining details in the images, comparing places in the images, or even comparing the same place in different images taken with different spacecraft or at different times. Your target audience could be members of the public who want to explore the data for inspiration, or researchers who could use your app to conduct detailed studies.

How will you develop and illustrate a method to explore these massive amounts of visual data? Don’t forget to include an example that sufficiently demonstrates your idea. How will your app manage diverse data products: e.g., different images of Earth or space, images taken at different times, images taken in different colors of light, or images with different kinds of data such as laser altimeter images of Earth or the Moon? And remember the importance of the user interface; user-friendliness and practical capabilities for future usage are priorities for this app! For example, you could envision how your app could be used in a public setting such as a science museum.

Potential Considerations
You may (but are not required to) consider the following:

Your app could:
Allow users to search through a large image by multiple means, such as entering coordinates, names of features, or even an artificial intelligence (AI)-powered text description of what to look for.
Give users the option to overlay related image sets and explore them simultaneously.
Provide interactive capabilities to explore video imagery in both time and space.
Data storage: Given that large images imply large data storage, think about how your app will scale the images for the optimal user experience. Will it run only on a local computer with terabytes of storage? Will it run online with adaptive image serving so that the app doesn’t have to download all the data at once?
Data assembly: Keep in mind that many datasets are available only in small chunks, and so producing a full image of Earth, for example, could require stitching together many individual partial images. Don’t forget that the purpose of this challenge isn’t to solve the problems of how to assemble the data, but rather to solve the problems of how to make the data easily explored and visualized by the user.